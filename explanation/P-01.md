# P-01:LLM利用に関するポリシーの整備
## 概要
LLMを利用した生成AIの多くは、Webブラウザなどから簡単に利用でき、無料で使い始めることができます。また、テキストだけでなく、WordやExcel、PDFなどのファイル、画像や音声、さらにはプログラムのソースコードの入出力や実行にも対応しているものもあります。

しかし、機密情報や個人情報などの組織が保有する情報を誤って生成AIに入力すると、情報漏洩につながる可能性があります。これは、生成AIプロバイダーが学習データや監査データとして入力情報を保持する場合があり、適切な設定を行わないと情報が流出するリスクがあるためです。企業向けプランでは、データを学習に利用しないオプションが提供されている場合もあるため、事前に確認が必要です。

また、生成AIの出力には事実誤認やバイアス、コンテキストの欠落が含まれることがあり、特に法律・医療・金融などの専門分野では、誤情報が重大な影響を及ぼす可能性があります。そのため、生成物を過信せず、利用者自身が内容を確認することが重要です。

さらに、生成AIの出力が既存の著作物と類似または部分的に一致する場合、著作権侵害に該当する可能性があります。特に、学習データに著作物が含まれている場合、AIがその内容を再現するリスクがあるため、商用利用時には著作権チェックを徹底する必要があります。

組織で生成AIサービスを利用する際には、AI利用ポリシーを策定し、以下のポイントを明確にすることが重要です。

* 入力制限：機密情報・個人情報の入力を禁止する。
* 出力確認：虚偽情報・著作権侵害のリスクを検証する手順を定める。
* 利用範囲：商用利用の可否、業務適用のルールを設定する。
* データ保持：使用するAIプラットフォームのデータ保持方針を確認する。

適切なポリシーとルールを整備することで、安全かつ効果的に生成AIを活用することができます。

## 対策
生成AIを安全に活用するためには、組織全体で統一された利用ポリシーを策定し、明確なルールのもとで運用することが重要です。以下のポイントを盛り込んだポリシーを整備し、全社的に周知・徹底しましょう。  

* 責任体制の明確化  
    - 生成AIの開発・運用の責任部署と担当者を定義し、適切な管理体制を構築する。  
    - AI導入・利用に関する承認プロセスを設定し、適用範囲やリスクを管理する。  
    - リスク承認の決定レイヤーを明示し、経営会議、リスク管理委員会、IT部門などが適切に関与する仕組みを整備する。  

 * 利用ルールと禁止事項の策定  
    - 機密情報・個人情報の入力を禁止し、誤って入力しないためのチェック体制を整える。  
    - 業務で利用可能な生成AIサービスを指定し、安全なプラットフォームを使用するよう統制する。  
    - 著作権・商標権のリスクを考慮し、生成物の商用利用や公開時の審査プロセスを設ける。  

* 例外承認プロセスの設定  
    - 機密データを利用する必要がある場合の例外承認フローを明示し、適切な管理下で利用するルールを定める。  
    - プラットフォーム側でデータが保持されるケースについては、情報セキュリティ部門・法務部門の承認を義務化し、監査可能な体制を確立する。  

 * 運用のモニタリングと定期的な見直し  
    - 生成AIの利用ログを監査し、不適切な利用がないか定期的にチェックする。  
    - 技術・法規制の変化に応じてポリシーを定期的に更新し、組織のリスク管理レベルを維持する。  
    - 従業員向けのトレーニングを実施し、ポリシーの遵守を徹底する。  


参考になるガイドラインとしては、独立行政法人情報処理推進機構や一般社団法人日本ディープラーニング協会が公開しているガイドラインなどがあります。ひな形を参考に組織の利用目的や用途に応じてカスタマイズし、ガイドラインを制定し運用していきましょう。適切なポリシーを策定・運用することで、組織として生成AIを安全かつ効果的に活用できる環境を整えていきましょう。


## 参考資料
* テキスト生成AIの導入・運用ガイドライン - 独立行政法人情報処理推進機構
    * https://www.ipa.go.jp/jinzai/ics/core_human_resource/final_project/2024/generative-ai-guideline.html
  
* 生成AIの利用ガイドライン - 一般社団法人日本ディープラーニング協会
    * https://www.jdla.org/document/#ai-guideline